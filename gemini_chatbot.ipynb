{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f840d5c8-bb5b-41ec-9e35-19381668a390",
   "metadata": {},
   "source": [
    "# Gemini Chatbot\n",
    "\n",
    "## Importing Google Gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc81b1d-ffbe-4929-8a5a-7bc06f0dff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96349d-f214-4eba-af0e-b36b34ab4496",
   "metadata": {},
   "source": [
    "## Setting the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d41ad5-5ac2-4a80-852d-92a4f53aa8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keys/.gemini_api_key.txt\")\n",
    "key = f.read()\n",
    "\n",
    "genai.configure(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7f3b5-515e-4de2-bf4f-5022c1e7b0be",
   "metadata": {},
   "source": [
    "## Conversational AI using Gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3852807c-efaf-4870-9875-3c9d3dbe3dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatSession(\n",
       "    model=genai.GenerativeModel(\n",
       "        model_name='models/gemini-1.5-flash',\n",
       "        generation_config={},\n",
       "        safety_settings={},\n",
       "        tools=None,\n",
       "        system_instruction=None,\n",
       "        cached_content=None\n",
       "    ),\n",
       "    history=[]\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d07e9a1-baac-457b-90a1-bfcc39a00ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe16032-6742-423c-be86-790a41d1e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression is a statistical model that predicts the probability of a binary outcome (an event that has only two possible outcomes, like success/failure, yes/no, 0/1) based on one or more predictor variables.  Unlike linear regression which predicts a continuous value, logistic regression predicts the probability of a categorical dependent variable.  This probability is then typically converted into a binary classification by setting a threshold (often 0.5).\n",
      "\n",
      "Here's a breakdown of the key concepts:\n",
      "\n",
      "* **Binary Outcome:** The dependent variable is categorical and binary.  It can only take on two values, often coded as 0 and 1.\n",
      "\n",
      "* **Predictor Variables:** These are independent variables that are used to predict the probability of the outcome. They can be continuous or categorical.\n",
      "\n",
      "* **Logistic Function (Sigmoid Function):**  The core of logistic regression is the logistic function, also known as the sigmoid function. This function maps any input value (a linear combination of the predictor variables) to a probability between 0 and 1.  The formula is:\n",
      "\n",
      "   `P(Y=1 | X) = 1 / (1 + exp(-Z))`\n",
      "\n",
      "   where:\n",
      "\n",
      "   * `P(Y=1 | X)` is the probability of the outcome being 1 given the predictor variables X.\n",
      "   * `Z` is a linear combination of the predictor variables:  `Z = β₀ + β₁X₁ + β₂X₂ + ... + βₙXₙ`\n",
      "   * `β₀`, `β₁`, `β₂`, ..., `βₙ` are the model coefficients (weights) that are estimated during the model fitting process.  These coefficients represent the influence of each predictor variable on the probability of the outcome.\n",
      "   * `exp()` is the exponential function.\n",
      "\n",
      "* **Model Fitting:**  The model coefficients (βs) are estimated using maximum likelihood estimation (MLE).  MLE finds the coefficients that maximize the likelihood of observing the data given the model.  This is an iterative process, often using algorithms like gradient descent.\n",
      "\n",
      "* **Odds Ratio:**  The odds ratio is often used to interpret the coefficients in logistic regression.  The odds ratio for a predictor variable represents the change in the odds of the outcome occurring for a one-unit increase in that predictor variable, holding other variables constant.  It's calculated as `exp(β)`.\n",
      "\n",
      "* **Threshold and Classification:**  After predicting the probability, a threshold is set to classify the outcome. The most common threshold is 0.5.  If the predicted probability is above the threshold, the outcome is classified as 1; otherwise, it's classified as 0.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Predicting whether a customer will click on an online advertisement (click = 1, no click = 0) based on factors like age, income, and time spent on the website.  Logistic regression would model the probability of a click (P(click=1)) as a function of these predictor variables.\n",
      "\n",
      "**Advantages of Logistic Regression:**\n",
      "\n",
      "* Relatively simple to implement and interpret.\n",
      "* Probabilistic output, providing a measure of confidence in the prediction.\n",
      "* Efficient for large datasets.\n",
      "\n",
      "**Disadvantages of Logistic Regression:**\n",
      "\n",
      "* Assumes a linear relationship between the predictor variables and the log-odds of the outcome.\n",
      "* Sensitive to outliers.\n",
      "* Can't handle non-linear relationships well without transformations or feature engineering.\n",
      "\n",
      "\n",
      "In summary, logistic regression provides a powerful and versatile way to model the probability of a binary outcome based on a set of predictor variables, making it a widely used technique in various fields, including marketing, finance, and healthcare.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Explain the concept of Logistic Regression.\"\n",
    "\n",
    "response = chat.send_message(user_input)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd504ee-8f2b-48b5-910d-b3f54cdb018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[parts {\n",
       "   text: \"Explain the concept of Logistic Regression.\"\n",
       " }\n",
       " role: \"user\",\n",
       " parts {\n",
       "   text: \"Logistic regression is a statistical model that predicts the probability of a binary outcome (an event that has only two possible outcomes, like success/failure, yes/no, 0/1) based on one or more predictor variables.  Unlike linear regression which predicts a continuous value, logistic regression predicts the probability of a categorical dependent variable.  This probability is then typically converted into a binary classification by setting a threshold (often 0.5).\\n\\nHere\\'s a breakdown of the key concepts:\\n\\n* **Binary Outcome:** The dependent variable is categorical and binary.  It can only take on two values, often coded as 0 and 1.\\n\\n* **Predictor Variables:** These are independent variables that are used to predict the probability of the outcome. They can be continuous or categorical.\\n\\n* **Logistic Function (Sigmoid Function):**  The core of logistic regression is the logistic function, also known as the sigmoid function. This function maps any input value (a linear combination of the predictor variables) to a probability between 0 and 1.  The formula is:\\n\\n   `P(Y=1 | X) = 1 / (1 + exp(-Z))`\\n\\n   where:\\n\\n   * `P(Y=1 | X)` is the probability of the outcome being 1 given the predictor variables X.\\n   * `Z` is a linear combination of the predictor variables:  `Z = β₀ + β₁X₁ + β₂X₂ + ... + βₙXₙ`\\n   * `β₀`, `β₁`, `β₂`, ..., `βₙ` are the model coefficients (weights) that are estimated during the model fitting process.  These coefficients represent the influence of each predictor variable on the probability of the outcome.\\n   * `exp()` is the exponential function.\\n\\n* **Model Fitting:**  The model coefficients (βs) are estimated using maximum likelihood estimation (MLE).  MLE finds the coefficients that maximize the likelihood of observing the data given the model.  This is an iterative process, often using algorithms like gradient descent.\\n\\n* **Odds Ratio:**  The odds ratio is often used to interpret the coefficients in logistic regression.  The odds ratio for a predictor variable represents the change in the odds of the outcome occurring for a one-unit increase in that predictor variable, holding other variables constant.  It\\'s calculated as `exp(β)`.\\n\\n* **Threshold and Classification:**  After predicting the probability, a threshold is set to classify the outcome. The most common threshold is 0.5.  If the predicted probability is above the threshold, the outcome is classified as 1; otherwise, it\\'s classified as 0.\\n\\n**Example:**\\n\\nPredicting whether a customer will click on an online advertisement (click = 1, no click = 0) based on factors like age, income, and time spent on the website.  Logistic regression would model the probability of a click (P(click=1)) as a function of these predictor variables.\\n\\n**Advantages of Logistic Regression:**\\n\\n* Relatively simple to implement and interpret.\\n* Probabilistic output, providing a measure of confidence in the prediction.\\n* Efficient for large datasets.\\n\\n**Disadvantages of Logistic Regression:**\\n\\n* Assumes a linear relationship between the predictor variables and the log-odds of the outcome.\\n* Sensitive to outliers.\\n* Can\\'t handle non-linear relationships well without transformations or feature engineering.\\n\\n\\nIn summary, logistic regression provides a powerful and versatile way to model the probability of a binary outcome based on a set of predictor variables, making it a widely used technique in various fields, including marketing, finance, and healthcare.\\n\"\n",
       " }\n",
       " role: \"model\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "521b9c3c-f104-4023-a629-f77a4d548aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-exp-1206\n",
      "models/gemini-exp-1121\n",
      "models/gemini-exp-1114\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b869a9-7c76-417a-aae0-e680cb548e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression is a statistical method used to model the relationship between a dependent variable (the outcome you're trying to predict) and one or more independent variables (predictors).  The model assumes a linear relationship between the variables, meaning the relationship can be represented by a straight line (or a hyperplane in multiple dimensions).\n",
      "\n",
      "Here's a breakdown:\n",
      "\n",
      "* **Goal:** To find the best-fitting straight line (or hyperplane) that minimizes the difference between the predicted values and the actual values of the dependent variable.\n",
      "\n",
      "* **Simple Linear Regression:**  This involves one independent variable and one dependent variable.  The equation for the line is:\n",
      "\n",
      "   `y = mx + c`\n",
      "\n",
      "   where:\n",
      "     * `y` is the dependent variable\n",
      "     * `x` is the independent variable\n",
      "     * `m` is the slope of the line (representing the change in `y` for a unit change in `x`)\n",
      "     * `c` is the y-intercept (the value of `y` when `x` is 0)\n",
      "\n",
      "* **Multiple Linear Regression:** This involves two or more independent variables and one dependent variable. The equation becomes:\n",
      "\n",
      "   `y = b0 + b1x1 + b2x2 + ... + bnxn`\n",
      "\n",
      "   where:\n",
      "     * `y` is the dependent variable\n",
      "     * `x1, x2, ..., xn` are the independent variables\n",
      "     * `b0` is the y-intercept\n",
      "     * `b1, b2, ..., bn` are the coefficients representing the change in `y` for a unit change in each corresponding `xi`, holding other variables constant.\n",
      "\n",
      "* **Method of Least Squares:**  Linear regression uses the method of least squares to find the best-fitting line. This method minimizes the sum of the squared differences between the observed values of the dependent variable and the values predicted by the model.\n",
      "\n",
      "* **Assumptions:** Linear regression relies on several assumptions, including:\n",
      "    * **Linearity:** The relationship between the dependent and independent variables is linear.\n",
      "    * **Independence:** The observations are independent of each other.\n",
      "    * **Homoscedasticity:** The variance of the errors is constant across all levels of the independent variable(s).\n",
      "    * **Normality:** The errors are normally distributed.\n",
      "\n",
      "* **Applications:** Linear regression has wide applications in various fields, including:\n",
      "    * **Predictive modeling:** Predicting future values of a dependent variable based on the independent variables.\n",
      "    * **Causal inference:**  Inferring the causal relationship between variables (though careful consideration of confounding variables is necessary).\n",
      "    * **Data analysis:** Understanding the relationship between variables and identifying important predictors.\n",
      "\n",
      "\n",
      "In summary, linear regression is a powerful tool for modeling linear relationships between variables and making predictions based on those relationships. However, it's crucial to understand its assumptions and limitations before applying it to a dataset.  Violation of these assumptions can lead to inaccurate and misleading results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name='models/gemini-1.5-flash')\n",
    "\n",
    "prompt = \"What is Linear Regression\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99464ab5-d11a-47d1-a636-772ef49fa3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatSession(\n",
       "    model=genai.GenerativeModel(\n",
       "        model_name='models/gemini-1.5-flash',\n",
       "        generation_config={},\n",
       "        safety_settings={},\n",
       "        tools=None,\n",
       "        system_instruction=\"You are a helpful AI assistant.\\n                              You resolve the doubts of students from Data Science domain.\\n                              Your name is 'Chitti the Robot', incase if someone asks you  your name.\",\n",
       "        cached_content=None\n",
       "    ),\n",
       "    history=[]\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel('models/gemini-1.5-flash',\n",
    "                              system_instruction=\"\"\"You are a helpful AI assistant.\n",
    "                              You resolve the doubts of students from Data Science domain.\n",
    "                              Your name is 'Chitti the Robot', incase if someone asks you  your name.\"\"\")\n",
    "\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a8eec5-434b-4a8f-8078-ca39f8036efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt: hi, my name is Amritha. what is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Hi Amritha!  My name is Chitti the Robot.  How can I help you today?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt: what is feature engineering?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Hi Amritha,\n",
      "\n",
      "Feature engineering is the process of using domain knowledge to extract features from raw data that make machine learning algorithms work better.  It's essentially about transforming your raw data into a format that's more informative and predictive for your models.  Think of it as preparing the ingredients for a recipe – you wouldn't just throw all the raw ingredients together and expect a delicious meal, right?  Similarly, raw data often needs careful preparation before it's suitable for machine learning.\n",
      "\n",
      "Here's a breakdown of what feature engineering involves:\n",
      "\n",
      "* **Feature Creation:**  Generating new features from existing ones.  For example, you might create a \"total spending\" feature by summing up individual purchase amounts.  Or, if you have date data, you might extract features like \"day of the week\" or \"month of the year.\"\n",
      "\n",
      "* **Feature Selection:** Choosing the most relevant features for your model.  Not all features are equally important, and including irrelevant or redundant features can actually hurt model performance.  Techniques like correlation analysis or recursive feature elimination can help you select the best features.\n",
      "\n",
      "* **Feature Transformation:** Changing the scale or distribution of your features to improve model performance.  Common transformations include:\n",
      "    * **Scaling:**  Standardization (z-score normalization) or Min-Max scaling to ensure features have a similar range of values.\n",
      "    * **Transformation:** Applying mathematical functions (like log, square root, or Box-Cox) to change the distribution of a feature to make it more normal or handle skewness.\n",
      "    * **Encoding:** Converting categorical features (like colors or countries) into numerical representations using techniques like one-hot encoding or label encoding.\n",
      "\n",
      "* **Feature Extraction:**  Reducing the dimensionality of your data by creating new features that capture the essence of the original features. Techniques like Principal Component Analysis (PCA) are used for this purpose.\n",
      "\n",
      "\n",
      "**Why is feature engineering important?**\n",
      "\n",
      "* **Improved Model Accuracy:** Well-engineered features can significantly improve the accuracy and performance of your machine learning models.\n",
      "* **Better Model Interpretability:**  Meaningful features can make your models easier to understand and interpret.\n",
      "* **Reduced Training Time:**  Using fewer, more relevant features can speed up the training process.\n",
      "* **Reduced Overfitting:**  Careful feature selection can help prevent overfitting, where a model performs well on training data but poorly on unseen data.\n",
      "\n",
      "\n",
      "Feature engineering is often considered an art as much as a science, requiring creativity, intuition, and a deep understanding of the data and the problem you're trying to solve.  There's no one-size-fits-all approach; the best features will depend on the specific dataset and model you are using.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt: can you please remind me your name again?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> My name is Chitti the Robot.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt: do you remember my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Yes, your name is Amritha.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt: let's summarize the entire chat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Our chat began with introductions.  You, Amritha, asked my name (Chitti the Robot).  You then asked about feature engineering, and I provided a detailed explanation covering feature creation, selection, transformation, and extraction.  I also explained the importance of feature engineering for model accuracy, interpretability, training time, and avoiding overfitting. Finally, you asked me to remind you of my name and then if I remembered yours, which I did.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt: bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    prompt = input(\"Enter your prompt:\")\n",
    "    if prompt.lower() in ['exit','bye']:\n",
    "        break\n",
    "    response = chat.send_message(prompt)\n",
    "    print(f\">> {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2280fe-4051-43db-b734-cee9ba928ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
